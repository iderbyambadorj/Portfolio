{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "First part of the preprocessing step includes basic transformations, such as converting data types, changing column names, etc. \n",
    "Second part includes filtering, feature selection, feature engineering and aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/geopandas/_compat.py:124: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/var/folders/np/m1q4q1w54q59sj70tvylvg5m0000gn/T/ipykernel_4009/2243204093.py:3: DeprecationWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas still uses PyGEOS by default. However, starting with version 0.14, the default will switch to Shapely. To force to use Shapely 2.0 now, you can either uninstall PyGEOS or set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In the next release, GeoPandas will switch to using Shapely by default, even if PyGEOS is installed. If you only have PyGEOS installed to get speed-ups, this switch should be smooth. However, if you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/21 07:24:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "import geopandas as gpd\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1 - Preprocessing\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the schema\n",
    "The dataset has different data types over different timelines. We need to use common schema to fix this issue. In addition, make sure that all columns are lower cased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sdf_feb_yellow = spark.read.parquet('../data/landing/yellow-2023-02.parquet')\n",
    "\n",
    "low_casing = [F.col(col_name).alias(col_name.lower()) for col_name in sdf_feb_yellow.columns]\n",
    "sdf_feb_yellow = sdf_feb_yellow.select(*low_casing)\n",
    "\n",
    "sdf_schema_yellow = sdf_feb_yellow.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/21 07:24:21 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "YEAR = '2022'\n",
    "MONTHS = range(1, 13)\n",
    "\n",
    "timelines = []\n",
    "for month in MONTHS:\n",
    "    timelines.append(YEAR + \"-\" + str(month).zfill(2))\n",
    "\n",
    "YEAR = '2023'\n",
    "MONTHS = range(1, 6)\n",
    "for month in MONTHS:\n",
    "    timelines.append(YEAR + \"-\" + str(month).zfill(2))\n",
    "\n",
    "for timeline in timelines:\n",
    "    sdf_yellow = spark.read \\\n",
    "        .parquet('../data/landing/yellow-'+timeline+'.parquet') \\\n",
    "        .select(*low_casing)\n",
    "    sdf_yellow = sdf_yellow \\\n",
    "        .select([F.col(c).cast(sdf_schema_yellow[i].dataType) for i, c in enumerate(sdf_yellow.columns)])\n",
    "    sdf_yellow \\\n",
    "        .coalesce(1) \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet('../data/raw/yellow/yellow-'+timeline)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.read.parquet('../data/raw/yellow/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "In this section, we changed data types and performed filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = sdf \\\n",
    "    .withColumn('duration_sec', F.unix_timestamp(F.col('tpep_dropoff_datetime')) - F.unix_timestamp(F.col('tpep_pickup_datetime'))) \\\n",
    "    .withColumn('passenger_count', F.col('passenger_count').cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------+\n",
      "|vendorid|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|ratecodeid|store_and_fwd_flag|pulocationid|dolocationid|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|duration_sec|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------+\n",
      "|       1| 2022-10-01 00:03:41|  2022-10-01 00:18:39|              1|          1.7|         1|                 N|         249|         107|           1|        9.5|  3.0|    0.5|      2.65|         0.0|                  0.3|       15.95|                 2.5|        0.0|         898|\n",
      "|       2| 2022-10-01 00:14:30|  2022-10-01 00:19:48|              2|         0.72|         1|                 N|         151|         238|           2|        5.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         9.3|                 2.5|        0.0|         318|\n",
      "|       2| 2022-10-01 00:27:13|  2022-10-01 00:37:41|              1|         1.74|         1|                 N|         238|         166|           1|        9.0|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|                 0.0|        0.0|         628|\n",
      "|       1| 2022-10-01 00:32:53|  2022-10-01 00:38:55|              0|          1.3|         1|                 N|         142|         239|           1|        6.5|  3.0|    0.5|      2.05|         0.0|                  0.3|       12.35|                 2.5|        0.0|         362|\n",
      "|       1| 2022-10-01 00:44:55|  2022-10-01 00:50:21|              0|          1.0|         1|                 N|         238|         166|           1|        6.0|  0.5|    0.5|       1.8|         0.0|                  0.3|         9.1|                 0.0|        0.0|         326|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- vendorid: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- ratecodeid: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- pulocationid: integer (nullable = true)\n",
      " |-- dolocationid: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- duration_sec: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show(5, truncate=100)\n",
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare features\n",
    "All fare features must be positive. Although they won't be used, incorrect entries make the data instance untrustworthy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values must be positive\n",
      "Before removing:  55842484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing:  53435612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:================================================>       (13 + 2) / 15]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference:  2406872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"All values must be positive\")\n",
    "initial_count = sdf.count()\n",
    "print(\"Before removing: \", initial_count)\n",
    "sdf=sdf.filter((F.col('vendorid').between(1, 2)) &\n",
    "                (F.col('ratecodeid').between(1, 6)) &\n",
    "                (F.col('payment_type').between(1, 6)) &\n",
    "                (F.col('fare_amount') >= 0) &\n",
    "                (F.col('extra') >= 0) &\n",
    "                (F.col('improvement_surcharge') >= 0) &\n",
    "                (F.col('tip_amount') >= 0) &\n",
    "                (F.col('fare_amount') >= 0) &\n",
    "                (F.col('tolls_amount') >= 0) &\n",
    "                (F.col('total_amount') >= 0) &\n",
    "                (F.col('congestion_surcharge') >= 0) &\n",
    "                (F.col('airport_fee') >= 0))\n",
    "print(\"After removing: \", sdf.count())\n",
    "print(\"Difference: \", initial_count - sdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passenger count must be positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing:  53435612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing:  50902107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:================================================>       (13 + 2) / 15]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference:  2533505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Passenger count\n",
    "print(\"Passenger count must be positive\")\n",
    "\n",
    "initial_count = sdf.count()\n",
    "print(\"Before removing: \", initial_count)\n",
    "sdf = sdf.filter(F.col('passenger_count').between(1, 4))\n",
    "print(\"After removing: \", sdf.count())\n",
    "print(\"Difference: \", initial_count - sdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip distance must be within the specified range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing:  50902107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing:  50180416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 61:================================================>       (13 + 2) / 15]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference:  721691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# trip distance\n",
    "print(\"Trip distance must be within the specified range\")\n",
    "MIN_DISTANCE = 0.1\n",
    "MAX_DISTANCE = 50\n",
    "\n",
    "initial_count = sdf.count()\n",
    "print(\"Before removing: \", initial_count)\n",
    "sdf = sdf.filter(F.col('trip_distance').between(MIN_DISTANCE, MAX_DISTANCE))\n",
    "print(\"After removing: \", sdf.count())\n",
    "print(\"Difference: \", initial_count - sdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location IDs must be between 1 and 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing:  50180416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing:  49373274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:================================================>       (13 + 2) / 15]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference:  807142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Location ID: Pick-up and Drop-off\n",
    "print(\"Location IDs must be between 1 and 263\")\n",
    "\n",
    "initial_count = sdf.count()\n",
    "print(\"Before removing: \", initial_count)\n",
    "sdf = sdf \\\n",
    "    .filter(F.col('pulocationid').between(1, 263)) \\\n",
    "    .filter(F.col('dolocationid').between(1, 263))\n",
    "print(\"After removing: \", sdf.count())\n",
    "print(\"Difference: \", initial_count - sdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing:  49373274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing:  48894121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 79:================================================>       (13 + 2) / 15]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference:  479153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Pickup time\n",
    "start_date = \"2022-01-01\"\n",
    "end_date = \"2023-06-01\"\n",
    "MIN_DURATION = 120 # 2 minutes\n",
    "MAX_DURATION = 14400 # 4 hours\n",
    "\n",
    "initial_count = sdf.count()\n",
    "print(\"Before removing: \", initial_count)\n",
    "sdf = sdf \\\n",
    "    .filter(F.col('tpep_pickup_datetime') >= start_date) \\\n",
    "    .filter(F.col('duration_sec').between(MIN_DURATION, MAX_DURATION)) \\\n",
    "    .filter(F.col('tpep_dropoff_datetime') < end_date)\n",
    "\n",
    "print(\"After removing: \", sdf.count())\n",
    "print(\"Difference: \", initial_count - sdf.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "We have decided to drop features related to specific trips since we are dealing with total number of pickup and dropoff counts for a certain time period instead of single trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = sdf.drop('ratecodeid', 'store_and_fwd_flag', 'payment_type', \n",
    "        'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', \n",
    "        'improvement_surcharge', 'total_amount', 'congestion_surcharge',\n",
    "        'airport_fee', 'vendorid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "We converted datetime features to nearest hours and extracted day, season information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = sdf \\\n",
    "    .withColumn('pickup_hour', F.hour((F.round(F.unix_timestamp('tpep_pickup_datetime')/3600)*3600).cast(\"timestamp\"))) \\\n",
    "    .withColumn('pickup_dayofweek', F.dayofweek('tpep_pickup_datetime')) \\\n",
    "    .withColumn('pickup_month', F.month('tpep_pickup_datetime')) \\\n",
    "    .withColumn('dropoff_hour', F.hour((F.round(F.unix_timestamp('tpep_dropoff_datetime')/3600)*3600).cast(\"timestamp\"))) \\\n",
    "    .withColumn('dropoff_dayofweek', F.dayofweek('tpep_dropoff_datetime')) \\\n",
    "    .withColumn('dropoff_month', F.month('tpep_dropoff_datetime')) \\\n",
    "    .withColumn('year', F.year('tpep_pickup_datetime'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Season is hardly likely to change. A single trip cannot have the effect\n",
    "# of two seasons at the same time. \n",
    "sdf = sdf.withColumn('season', F.when((F.col('pickup_month').between(3, 5)), 'spring')\n",
    "                            .when((F.col('pickup_month').between(6, 8)), 'summer')\n",
    "                            .when((F.col('pickup_month').between(9, 11)), 'autumn')\n",
    "                            .otherwise('winter'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "Group the dataset using temporal and spatial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup = sdf.groupBy(\"pulocationid\", \"pickup_hour\", \"pickup_dayofweek\", \"season\", \"year\").agg(\n",
    "    F.count(F.col(\"pulocationid\")).alias(\"pickup_count\")\n",
    ")\n",
    "dropoff = sdf.groupBy(\"dolocationid\", \"dropoff_hour\", \"dropoff_dayofweek\", \"season\", \"year\").agg(\n",
    "    F.count(F.col(\"dolocationid\")).alias(\"dropoff_count\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pulocationid: integer (nullable = true)\n",
      " |-- pickup_hour: integer (nullable = true)\n",
      " |-- pickup_dayofweek: integer (nullable = true)\n",
      " |-- season: string (nullable = false)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- pickup_count: long (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total instances of pickup data:  129673\n",
      "root\n",
      " |-- dolocationid: integer (nullable = true)\n",
      " |-- dropoff_hour: integer (nullable = true)\n",
      " |-- dropoff_dayofweek: integer (nullable = true)\n",
      " |-- season: string (nullable = false)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- dropoff_count: long (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 88:====================================================>   (14 + 1) / 15]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total instances of dropoff data:  231653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pickup.printSchema()\n",
    "print(\"Total instances of pickup data: \", pickup.count())\n",
    "dropoff.printSchema()\n",
    "print(\"Total instances of dropoff data: \", dropoff.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the taxi data to the public transport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "public_transport = spark.read.csv('../data/raw/public_transport.csv', header=True, inferSchema=True)\n",
    "pickup = pickup.join(public_transport.select('LocationID', 'Shape_Area', 'borough', 'num_stops'), \n",
    "                pickup['pulocationid'] == public_transport['LocationID'], how='inner')\n",
    "dropoff = dropoff.join(public_transport.select('LocationID', 'Shape_Area', 'borough', 'num_stops'), \n",
    "                dropoff['dolocationid'] == public_transport['LocationID'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup = pickup.drop('LocationID')\n",
    "dropoff = dropoff.drop('LocationID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airport\n",
    "Ensure borough value is Airport for taxi zones with airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = gpd.read_file(\"../data/landing/taxi_zones/taxi_zones.shp\")\n",
    "airport_location_id = []\n",
    "for location_id in zone.loc[zone['zone'].str.contains('Airport'), ['LocationID']].values:\n",
    "    airport_location_id.append(location_id[0])    \n",
    "pickup = pickup.withColumn(\"borough\", F.when(F.col(\"pulocationid\").isin(airport_location_id), 'Airport').otherwise(F.col(\"borough\")))\n",
    "dropoff = dropoff.withColumn(\"borough\", F.when(F.col(\"dolocationid\").isin(airport_location_id), 'Airport').otherwise(F.col(\"borough\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now clean and ready to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pickup.toPandas().to_csv('../data/curated/pickup.csv', index=False)\n",
    "dropoff.toPandas().to_csv('../data/curated/dropoff.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
